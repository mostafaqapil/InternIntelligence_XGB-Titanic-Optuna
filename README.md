# InternIntelligence_XGB-Titanic-Optuna

Overview

This project focuses on optimizing the hyperparameters of an XGBoost model using Optuna to improve its performance on the Titanic dataset.

Features

Data preprocessing & cleaning

Model training using XGBoost

Hyperparameter tuning with Optuna

Cross-validation for evaluation

Performance metrics analysis

Technologies Used

Python

Scikit-Learn

XGBoost

Optuna

Google Colab

esults

The model achieved high accuracy after hyperparameter tuning.

Performance metrics include accuracy, precision, recall, and F1-score.

Author

Developed by: Mostafa Qapil
